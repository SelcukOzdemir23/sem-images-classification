Found 8768 files belonging to 4 classes.
Using 5261 files for training.
Found 8768 files belonging to 4 classes.
Using 1753 files for validation.
Found 8768 files belonging to 4 classes.
Using 1753 files for validation.
<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>
<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>
<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>
Model: "sequential_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 sequential_5 (Sequential)   (None, 256, 256, 3)       0
 conv2d_2 (Conv2D)           (None, 254, 254, 6)       168
 batch_normalization_5 (Bat  (None, 254, 254, 6)       24
 chNormalization)
 max_pooling2d_2 (MaxPoolin  (None, 127, 127, 6)       0
 g2D)
 dropout_2 (Dropout)         (None, 127, 127, 6)       0
 conv2d_3 (Conv2D)           (None, 125, 125, 16)      880
 batch_normalization_6 (Bat  (None, 125, 125, 16)      64
 chNormalization)
 max_pooling2d_3 (MaxPoolin  (None, 62, 62, 16)        0
 g2D)
 flatten_1 (Flatten)         (None, 61504)             0
 dense_6 (Dense)             (None, 1024)              62981120
 batch_normalization_7 (Bat  (None, 1024)              4096
 chNormalization)
 dropout_3 (Dropout)         (None, 1024)              0
 dense_7 (Dense)             (None, 128)               131200
 batch_normalization_8 (Bat  (None, 128)               512
 chNormalization)
 dense_8 (Dense)             (None, 3)                 387
=================================================================
Total params: 63118451 (240.78 MB)
Trainable params: 63116103 (240.77 MB)
Non-trainable params: 2348 (9.17 KB)
_________________________________________________________________
Model: "sequential_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 efficientnetb4 (Functional  (None, 8, 8, 1792)        17673823
 )
 global_average_pooling2d_1  (None, 1792)              0
  (GlobalAveragePooling2D)
 dense_9 (Dense)             (None, 1024)              1836032
 batch_normalization_9 (Bat  (None, 1024)              4096
 chNormalization)
 dense_10 (Dense)            (None, 128)               131200
 dense_11 (Dense)            (None, 3)                 387
=================================================================
Total params: 19645538 (74.94 MB)
Trainable params: 1969667 (7.51 MB)
Non-trainable params: 17675871 (67.43 MB)
_________________________________________________________________
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
Epoch 1/10
wandb: Appending key for api.wandb.ai to your netrc file: C:\Users\Ã–zdemir/.netrc